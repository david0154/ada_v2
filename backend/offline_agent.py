"""\nDayna AI - Offline Agent\nBilingual (Hindi + English) with Mistral-7B\n\nAuthor: David (Nexuzy Tech)\nLicense: MIT\n"""\n\nimport asyncio\nfrom typing import Optional, Literal\nfrom llama_cpp import Llama\nfrom faster_whisper import WhisperModel\nimport subprocess\nimport tempfile\nimport os\n\n\nclass OfflineAgent:\n    """\n    Offline AI Agent with bilingual support\n    - LLM: Mistral-7B-Instruct GGUF\n    - STT: Whisper (multilingual)\n    - TTS: Piper (Hindi + English)\n    """\n    \n    def __init__(\n        self,\n        model_path: str = "backend/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf",\n        whisper_model: str = "base",\n        hindi_voice: str = "backend/models/hi_IN-pratham-medium.onnx",\n        english_voice: str = "backend/models/en_US-lessac-medium.onnx",\n        n_threads: int = 8,\n        n_gpu_layers: int = 35\n    ):\n        print("[DAYNA OFFLINE] üöÄ Initializing..." )\n        \n        # Load Mistral-7B\n        print("[DAYNA OFFLINE] Loading Mistral-7B...")\n        self.llm = Llama(\n            model_path=model_path,\n            n_ctx=4096,\n            n_threads=n_threads,\n            n_gpu_layers=n_gpu_layers if self._has_gpu() else 0,\n            verbose=False\n        )\n        \n        # Load Whisper\n        print("[DAYNA OFFLINE] Loading Whisper STT...")\n        self.whisper = WhisperModel(\n            whisper_model,\n            device="cuda" if self._has_gpu() else "cpu",\n            compute_type="float16" if self._has_gpu() else "int8"\n        )\n        \n        # Store TTS paths\n        self.hindi_voice = hindi_voice\n        self.english_voice = english_voice\n        \n        self.conversation_history = []\n        print("[DAYNA OFFLINE] ‚úÖ Ready!")\n    \n    def _has_gpu(self) -> bool:\n        try:\n            import torch\n            return torch.cuda.is_available()\n        except:\n            return False\n    \n    def _detect_language(self, text: str) -> str:\n        """Detect if text is Hindi or English"""\n        # Check for Devanagari characters\n        devanagari = sum(1 for c in text if '\\u0900' <= c <= '\\u097F')\n        total = len([c for c in text if c.isalpha()])\n        \n        if total == 0:\n            return "en"\n        \n        return "hi" if (devanagari / total) > 0.3 else "en"\n    \n    async def transcribe_audio(self, audio_path: str) -> tuple[str, str]:\n        """Transcribe audio and detect language"""\n        segments, info = await asyncio.to_thread(\n            self.whisper.transcribe,\n            audio_path,\n            beam_size=5\n        )\n        \n        text = " ".join([s.text for s in segments]).strip()\n        return text, info.language\n    \n    async def generate_response(\n        self, \n        prompt: str, \n        language: str = "auto",\n        max_tokens: int = 512\n    ) -> tuple[str, str]:\n        """Generate response in detected language"""\n        \n        if language == "auto":\n            language = self._detect_language(prompt)\n        \n        # Bilingual system prompt\n        if language == "hi":\n            system = """‡§Ü‡§™ Dayna ‡§π‡•à‡§Ç, ‡§è‡§ï AI Assistant‡•§ ‡§Ü‡§™ ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡§º‡•Ä ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•à‡§Ç‡•§\nUser ‡§ú‡§ø‡§∏ ‡§≠‡§æ‡§∑‡§æ ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á, ‡§â‡§∏‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•á‡§Ç‡•§"""\n        else:\n            system = """You are Dayna, an AI Assistant. You can speak both Hindi and English.\nRespond in the same language as the user."""\n        \n        formatted = f"<s>[INST] {system}\\n\\n{prompt} [/INST]"\n        \n        response = await asyncio.to_thread(\n            self.llm,\n            formatted,\n            max_tokens=max_tokens,\n            temperature=0.7,\n            stop=["</s>"],\n            echo=False\n        )\n        \n        text = response['choices'][0]['text'].strip()\n        detected_lang = self._detect_language(text)\n        \n        return text, detected_lang\n    \n    async def synthesize_speech(\n        self,\n        text: str,\n        language: str = "auto"\n    ) -> bytes:\n        """Generate TTS audio"""\n        \n        if language == "auto":\n            language = self._detect_language(text)\n        \n        voice = self.hindi_voice if language == "hi" else self.english_voice\n        \n        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:\n            output_path = f.name\n        \n        process = await asyncio.create_subprocess_exec(\n            "piper",\n            "--model", voice,\n            "--output_file", output_path,\n            stdin=asyncio.subprocess.PIPE\n        )\n        \n        await process.communicate(input=text.encode('utf-8'))\n        \n        with open(output_path, 'rb') as f:\n            audio = f.read()\n        \n        os.unlink(output_path)\n        return audio\n\n\nif __name__ == "__main__":\n    async def test():\n        agent = OfflineAgent()\n        \n        # Test English\n        resp_en, lang = await agent.generate_response("Hello! What is your name?")\n        print(f"EN ({lang}): {resp_en}")\n        \n        # Test Hindi\n        resp_hi, lang = await agent.generate_response("‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ?")\n        print(f"HI ({lang}): {resp_hi}")\n    \n    asyncio.run(test())\n